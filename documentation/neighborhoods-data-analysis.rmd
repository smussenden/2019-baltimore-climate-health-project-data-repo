---
title: "Neighborhoods Analysis"
author: "Roxanne Ready, Sean Mussenden, Theresa Diffendal | Howard Center for Investigative Journalism"
date: "8/6/2019"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    df_print: paged
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 3
---

```{r include=FALSE}
# Save this file and run the following line from the Console to output both HTML and .md formats:
# rmarkdown::render('documentation/neighborhoods-data-analysis.Rmd', output_format = 'all')
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, paged.print=TRUE)
```

## Introduction

REWRITE
This R markdown document describes the methodology and results of a portion of the data analysis we conducted in support of a reporting project examining the effects of tree canopy inequity across the city of Baltimore, especially as it relates to climate change.

In general, this document contains the data facts stated in the "Neighborhoods" story. The quote from the story appears first, followed by an explanation of the fact and the code which generated the fact. The code is listed last. 

## Setup

Before running this file, **please view and run the [Code Red Data Cleaning document](https://github.com/smussenden/2019-baltimore-climate-health-project-data-repo/blob/master/documentation/code-red-data-cleaning.md)** for this project. As well as outputting necessary cleaned data for the following ananlysis, that document also includes the following items necessary to understand this analysis: 

* definitions
* source data citation and information
* cleaning methodology 
* software tools used

### Load packages

```{r}
#######################
#### Load Packages ####
#######################

library(tidyverse)
library(DescTools) # For %like% operator
library(corrr) # For correlation matrices
library(colorspace) # For improved color palettes
library(ggplot2) # For graphing
library(ggrepel) # For graph labeling
require(scales) # For percent labeling on distribution tables

# Turn off scientific notation in RStudio (prevents coersion to character type)
options(scipen = 999)
```

### Load variables and data

```{r}
#########################
#### Store Variables ####
#########################

#### Common path to data ####
path_to_data <- "../data/output-data/cleaned/"

#### Common save path ####
save_path <- "../data/output-data/cleaned/"

###################
#### Load Data ####
###################

dmh <- read_csv(paste0(path_to_data, "dmh.csv"))
EMS_all <- read_csv(paste0(path_to_data, "EMS_all.csv"))
dmh_ems <- read_csv(paste0(path_to_data, "dmh_ems.csv"))
stephanie_day_averages<- read_csv(paste0(path_to_data, "stephanie_day_averages.csv"))
stephanie_day_hourly_averages <- read_csv(paste0(path_to_data, "stephanie_day_hourly_averages.csv"))
stephanie_day_minute_averages <- read_csv(paste0(path_to_data, "stephanie_day_minute_averages.csv"))
tammy_day_averages <- read_csv(paste0(path_to_data, "tammy_day_averages.csv"))
tammy_day_hourly_averages <- read_csv(paste0(path_to_data, "tammy_day_hourly_averages.csv"))
tammy_day_minute_averages <- read_csv(paste0(path_to_data, "tammy_day_minute_averages.csv"))
michael_day_averages<- read_csv(paste0(path_to_data, "michael_day_averages.csv"))
michael_day_hourly_averages <- read_csv(paste0(path_to_data, "michael_day_hourly_averages.csv"))
michael_day_minute_averages <- read_csv(paste0(path_to_data, "michael_day_minute_averages.csv"))
nsa_tree_temp <- read_csv(paste0(path_to_data,"nsa_tree_temp.csv"))
csa_tree_temp_demographics <- read_csv(paste0(path_to_data,"csa_tree_temp_demographics.csv"))
blocks_tree_temp_demographics <- read_csv(paste0(path_to_data, "blocks_tree_temp_demographics.csv"))

####################################
######## Define Functions ##########
####################################

# Function to save each matrix as CSV
write_matrix_csv <- function(dataframe) {
  # Store dataframe name for later use
  dataframe_name <- deparse(substitute(dataframe))
  
  # Create filename for csv
  filename <- paste0("data/output-data/correlation_matrices/", dataframe_name,".csv")
  
  # Write out csv  
  write_csv(dataframe, path = filename)
  
} 

# Function to make a nice little correlation matrix heatmap for each graphic

make_correlation_matrix_graphic <- function(dataframe, grouping = "GROUPING") {
  
  # Store name of dataframe for use in title
  dataframe_name <- deparse(substitute(dataframe))
  
  # Build chart title
  chart_title <- paste0("Correlations by ", grouping, " in Baltimore City | ", dataframe_name )
  
  # Create graph
  ggplot(data = dataframe, aes(x = variable_2, y = variable)) +
    geom_tile(aes(fill = value)) +
    scale_fill_gradient2(low = "blue", high = "red", mid="white", midpoint=0) +
    geom_text(aes(label = round(value, 2)*100), size = 10) +
    ggtitle(chart_title) +
    theme(axis.text=element_text(size=14),
          axis.text.x = element_text(size=14,angle=50,hjust=1),
          plot.title = element_text(size=14)
    )
  # Create filename and filepath to save image. 
  filename <- paste0(dataframe_name,".png")
  ggsave(filename, plot = last_plot(), device = "png", path = "data/output-data/plots/correlation-matrix-images", scale = 1, width = 20, height = 20, units = "in", dpi = 300)
  
}  

select_x <- function(df){
  return(df %>%
           select_if(is.numeric) 
           # select(-matches("objectid"), 
           #        -matches("csa2010"), 
           #        -matches("id"), 
           #        -matches("09"), 
           #        -matches("1718"), 
           #        -matches("change_percent")
           #        )
         )
}

```

## Line-By-Line Fact-Check

### Fact: 11-Day Heat Wave

"...a dangerous, 11-day heat wave tormented the city this summer..."

#### Explanation

By running the code below, you can see July 12-22 had max temperatures of at least 90 degrees and max heat indexes of at least 92, hence the 11-day heat wave

#### Supporting Code
```{r}

 dmh %>%
  filter(month == 7,
         year == 2019) %>%
  group_by(`date`) %>%
  summarise(min_temp = min(avg_hourly_temperature_dmh),
            max_temp = max(avg_hourly_temperature_dmh),
            mean_temp = mean(avg_hourly_temperature_dmh),
            min_heat_index = min(avg_hourly_heat_index_dmh),
            max_heat_index = max(avg_hourly_heat_index_dmh),
            mean_heat_index = mean(avg_hourly_heat_index_dmh) 
  )


```

### Fact: Inner Harbor Hit 100 Degrees

"“Can’t even put your head out the door,” said Tammy Wilson Jackson, 48, on a day when the temperature at the Inner Harbor hit 100 degrees."

#### Explanation

Our data below shows that the inner harbor hit a max temperature of 100 on Sunday 7/21. There is no other day in our data when the max temperature was 100. However our data uses hourly averages. The National Climatic Data Center also takes weather data hour by hour, but instead of calculating the average the NCDC records the conditions at the exact time of the reading. NCDC also has daily summaries detailing the maximum and minimum temperature experienced over the entire day and the amount of precipitation in inches. Using the NCDC's daily summaries for the month of July 2019, there are two days when the max temperature hit at least 100: 7/20 and 7/21. 

Note: the max temperature on 7/30 was also 100 degrees, but this interview was before then.

#### Supporting Code
```{r}

 dmh %>%
 filter(month == 7,
         year == 2019) %>%
  group_by(`date`) %>%
  summarise(min_temp = min(avg_hourly_temperature_dmh),
            max_temp = max(avg_hourly_temperature_dmh),
            mean_temp = mean(avg_hourly_temperature_dmh),
            min_heat_index = min(avg_hourly_heat_index_dmh),
            max_heat_index = max(avg_hourly_heat_index_dmh),
            mean_heat_index = mean(avg_hourly_heat_index_dmh) 
  )


```

### Fact: McElderry Park is 8 Degrees Hotter

"data show that temperatures here [McElderry Park] and in surrounding neighborhoods can run 8 degrees hotter than in communities that have more trees and less pavement."

#### Explanation

The code below selects part of the dataframe "nsa_tree_temp" - which lists Baltimore neighborhoods and a variety of temperature data - and filters it for the neighborhoods with the lowest average temperature in the afternoon or the highest average temperature in the afternoon. The results are then arranged in descending order. From this data we can see that McElderry Park has the highest average temperature in the afternoon at 99.39 degrees. Dickeyville, on the other hand, has the lowest average afternoon temperature at 91.01 degrees. The difference between those temperatures is 8.38 degrees, which is rounded to 8.

*Note: Gwynns Falls/Leakin Park was removed from the dataset as the topography of the area is more akin to a park than neighborhood.

#### Supporting Code
```{r}
nsa_tree_temp %>%
  select(nsa_name, temp_mean_aft) %>%
  filter(nsa_name != "gwynns falls/leakin park") %>%
  filter((temp_mean_aft == min(temp_mean_aft)) | (temp_mean_aft == max(temp_mean_aft))) %>%
  arrange(desc(temp_mean_aft))
  
```

### Fact: McElderry Park is the hottest neighborhood in Baltimore

"McElderry Park ... which despite its lyrical name offers little green space, is the hottest neighborhood in Baltimore."

#### Explanation

Similar to above, the code below selects the neighborhood and average afternoon temperature columns from the dataframe "nsa_tree_temp" - which lists Baltimore neighborhoods and a variety of temperature data. The results are then arranged in descending order so the hottest neighborhood is at the top. From this data we can see that McElderry Park has the highest average temperature in the afternoon at 99.39 degrees. 

#### Supporting Code
```{r}
nsa_tree_temp %>%
  select(nsa_name, temp_mean_aft) %>%
  arrange(desc(temp_mean_aft))
  
```

### Fact: Frequency of EMS Calls Increase with Temperature

"In hot weather, emergency medical calls for some chronic conditions increase."

#### Explanation

The initial code below sorts the number of calls to EMS into groups based on the outside temperature when the call was made. You'll see that calls for help decrease as temperature increases. 

The second bit of code, however, breaks the calls down by the illness for which the call was made and counts the number of calls per condition during each temperature "bucket." Many of these illness were selected since hot weather tends to aggravate their symptoms/conditions. These numbers show that calls decrease as temperature increases, but a likely explanation is that hot temperatures occur much less frequently than cooler ones, limiting the amount of time when calls can be made in that temperature "bucket." 

To account for the rarity of hotter temperatures, the number of hours for which the temperature was in a certain bucket is divided by the total amount of calls. This will give us the frequency of calls, represented as "hours_per_call." In examining this value per condition per temperature bucket, the data shows that the freqeuency of many calls increases during hotter weather. 

For example, when the temperature is below 80 degrees, a call is made to EMS concerning dehydration every 41.74 hours. When the temperature climbs into the "danger" zone, or 103 to 124 degrees, the rate of calls for dehydration increases to one every 2.21 hours. Similarly, a call for a seizure is made every 2.34 hours when the temperature is less than 80 degrees, but increases to a call every 1.4 hours when the temperature is between 103 and 124 degrees. 

Other conditions for which the call frequency increases include: altered level of consciousness, behavioral/psychiatric disorder, cardiac arrest, chest pain - STEMI, COPD, dehydration, diabetic hyper- and hypoglycemia, dizziness/vertigo, hyper- and hypotension, hyperthermia, obvious death, substance/drug abuse, and others.

#### Supporting Code
```{r}

# Five-part NWS heat index danger scale
heat_index_count_per_nws_five_scale_bucket <- dmh_ems %>%
  select(heat_index_nws_five_scale_bucket) %>%
  group_by(heat_index_nws_five_scale_bucket) %>%
  summarise(heat_index_count_per_nws_five_scale_bucket=n()) %>%
  arrange(heat_index_nws_five_scale_bucket)

########### Five NWS Buckets #################
#### Table 1 | Primary Impression Group | Ratio Condition Calls v Heat Index | five NWS Buckets #####
# Ratio of number of calls for each condition type in each heat index bucket to total number of hours in each given temperature bucket. A lower number indicates a higher number of calls for each condition adjusted for the fact that some temperatures are simply more common than other others. It's 70 degrees for many more hours in a year than it is 110.  

call_heat_index_ratio_five_primary_impression_group <- EMS_all %>%
  filter(primary_impression_group != "Other") %>%
  group_by(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket) %>%
  summarise(condition_calls_count_per_bucket=n()) %>%
  inner_join(heat_index_count_per_nws_five_scale_bucket, by = c("adjusted_heat_index_nws_five_scale_bucket" = "heat_index_nws_five_scale_bucket")) %>%
  mutate(hours_per_call = heat_index_count_per_nws_five_scale_bucket/condition_calls_count_per_bucket) %>%
  select(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  spread(adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  select(primary_impression_group, `not_unsafe_under_80`,`caution_80_89`,`extreme_caution_90_102`,`danger_103_124`)

```

### Fact: Frequency of Diabetes Calls Increases with Temperature

"The rate of emergency medical calls for cardiac arrest and congestive heart failure, for example, nearly double when the heat index hits 103 degrees."

#### Explanation

Using the same code as above, the number of hours inbetween calls for diabetes are certain temperatures was calculated. At 80 degrees or below, a call was made every 5.3 hours for Cardiac Arrest and every 15 hours for Congestive Heart Failure. When the heat index is 103 or greater, however, there is a call to EMS for cardiac arrest every 2.94 hours and for congestive heart failure every 8.83 hours. By dividing the value at 80 degrees by the value at 103+, we will get 1.8 for cardiac arrest and 1.7 for congestive heart failure. Those numbers round to 2, which means the frequency of the calls nearly doubles. 

#### Supporting Code
```{r}

# Create dataframes with a count of hourly heat_index readings for each bucket ###

# Five-part NWS heat index danger scale
heat_index_count_per_nws_five_scale_bucket <- dmh_ems %>%
  select(heat_index_nws_five_scale_bucket) %>%
  group_by(heat_index_nws_five_scale_bucket) %>%
  summarise(heat_index_count_per_nws_five_scale_bucket=n()) %>%
  arrange(heat_index_nws_five_scale_bucket)

########### Five NWS Buckets #################
#### Table 1 | Primary Impression Group | Ratio Condition Calls v Heat Index | five NWS Buckets #####
# Ratio of number of calls for each condition type in each heat index bucket to total number of hours in each given temperature bucket. A lower number indicates a higher number of calls for each condition adjusted for the fact that some temperatures are simply more common than other others. It's 70 degrees for many more hours in a year than it is 110.

call_heat_index_ratio_five_primary_impression_group <- EMS_all %>%
  filter(primary_impression_group != "Other") %>%
  group_by(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket) %>%
  summarise(condition_calls_count_per_bucket=n()) %>%
  inner_join(heat_index_count_per_nws_five_scale_bucket, by = c("adjusted_heat_index_nws_five_scale_bucket" = "heat_index_nws_five_scale_bucket")) %>%
  mutate(hours_per_call = heat_index_count_per_nws_five_scale_bucket/condition_calls_count_per_bucket) %>%
  select(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  spread(adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  select(primary_impression_group, `not_unsafe_under_80`,`caution_80_89`,`extreme_caution_90_102`,`danger_103_124`) %>%
  filter(primary_impression_group == "Cardiac Arrest" | primary_impression_group == "CHF (Congestive Heart Failure)")

```

### Fact: Hot Neighborhoods Have Lower Incomes

"Households in the city’s hottest neighborhoods have lower incomes"

#### Explanation

The code below pulls from the "csa_tree_temp_demographics" dataset, which includes a variety of information on each neighborhood in Baltimore. From that dataset, median afternoon temperature and percentage of family households below the poverty line are isolated to allow for a comparison of median temperatures to poverty rate. The temperature is arranged in descending order, putting the hottest neighborhoods on top. 

The two hottest neighborhoods, Madison/East End and Oldtown/Middle East, have poverty rates of 33.74% and 40.13%, respectively. The ten hottest neighborhoods all have average afternoon temperatures of at least 96 (when rounded) and only two have single digit poverty rates; the poverty rates for the other neighborhoods are all at least 19%. 

In comparison, the 15 coolest neighborhoods have an average afternoon temperature of 94.1 degrees or less. The highest poverty rate is 19.53% in Greater Govans and 19.26% in Forest Park/Walbrook, only greater than the poverty rating of 7 of the 10 hottest neighborhoods. 8 of the coolest neighborhoods have a single digit poverty rating (or 7 neighborhoods, if you round Cross-Country/Cheswolde's poverty rate to 10%).

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("temp_")) %>%
  mutate(variable=rowname) %>%
  select(variable, temp_median_aft) %>%
  filter(variable=="percent_of_family_households_living_below_the_poverty_line")

csa_tree_temp_demographics %>%
  select(csa2010,temp_median_aft,percent_of_family_households_living_below_the_poverty_line) %>%
  arrange(desc(temp_median_aft))

```

### Fact: Unreliable Public Transportation

"Public transportation, which many residents here use, is unreliable."

#### Explanation

The code below returns Baltimore neighborhoods in descending order of average afternoon temperature as well as the percentage of that neighborhood's population that uses public transportation to get to work. Of all the neighborhoods, only 10 have single digit values for the percentage of population that uses public transportation. Of the top ten hottest neighborhoods, only one has a single digit public transportation usage value; the next lowest is 12.20% and the greatest is 42.55%. Over 30% of the population uses public transportation in 10 neighborhoods, and five of those neighbors are also among the ten hottest (six of the highest public transportation using neighborhoods are also among the 12 hottest). 

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("temp_")) %>%
  mutate(variable=rowname) %>%
  select(variable, temp_median_aft) %>%
  filter(variable=="percent_of_population_that_uses_public_transportation_to_get_to_work")

csa_tree_temp_demographics %>%
  select(csa2010,temp_median_aft,percent_of_population_that_uses_public_transportation_to_get_to_work) %>%
  arrange(desc(temp_median_aft))

```

### Fact: More Affluence = More Tree Canopy

"The streets have fewer trees than those in more affluent communities."

#### Explanation

The code below below selects from the neighborhood demographic dataset all the neighborhoods, the poverty rate in those neighborhoods, and the percentage of tree cover for each neighborhood according to the most recent LiDar data available for Baltimore from 2015. The selected observations are then listed in order of greatest tree canopy percentage to least.

The ggplot code then graphs that dataset, with special attention paid to the neighborhoods Canton, Clifton-Berea, Patterson Park, Greater Roland Park/Poplar Hill and Greenmount East. Along the y-axis is percentage of tree canopy coverage while the x-axis shows poverty rates. The code geom_smooth() creates a best fit line over the data and clearly shows a decrease in tree canopy coverage as poverty rate increases.

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("15_lid_mean")) %>%
  mutate(variable=rowname) %>%
  select(variable, `15_lid_mean`) %>%
  filter(variable=="percent_of_family_households_living_below_the_poverty_line")

csa_tree_temp_demographics %>%
  select(csa2010,`15_lid_mean`,percent_of_family_households_living_below_the_poverty_line) %>%
  arrange(desc(`15_lid_mean`))

# CSAs to call out
callout_ls <- c("Canton", "Clifton-Berea", "Greater Roland Park/Poplar Hill", "Greenmount East")

## POVERTY TO TREE COVER
csa_tree_temp_demographics %>%
  mutate_at(vars("csa2010"), str_to_title) %>%
  # Start ggplot and set x and y for entire plot
  ggplot(aes(
    x = percent_of_family_households_living_below_the_poverty_line/100,
    y = `15_lid_mean`
    )) +
  # This section for the basic scatterplot
  geom_point(aes(color = `15_lid_mean`),
             size=4) +
  # This section for circling all sample neighborhood points
  geom_point(data = csa_tree_temp_demographics %>%
               mutate_at(vars("csa2010"), str_to_title) %>%
               filter((csa2010 %in% callout_ls)
                      # Patterson Park must be included seperately because of its unique label positioning
                      | (csa2010 == "Patterson Park North & East")
                      ),
             aes(color = `15_lid_mean`),
             size=6, shape = 1) +
  # This section shows the trend line
  geom_smooth(se = FALSE, # Removes gray banding
              method = glm,
              color = "black") +
  # This section for labeling Canton, etc.
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 %in% callout_ls) %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Greenmount East" ~ "Greenmount East \n(includes part of Broadway East)",
                                csa2010 == "Clifton-Berea" ~ "Clifton-Berea \n(includes part of Broadway East)",
                                T ~ csa2010)),
            aes(label = csa2010),
            min.segment.length = .1,
            segment.alpha = .5,
            alpha = .85,
            nudge_x = .05,
            nudge_y = .06) +
  # This section for labeling Patterson Park (so its label can be nudged)
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 == "Patterson Park North & East") %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Patterson Park North & East" ~ "Patterson Park North & East \n(includes most of McElderry Park)",
                                T ~ csa2010)),
                            aes(label = csa2010),
                            min.segment.length = .1,
                            segment.alpha = .5,
                            alpha = .85,
                            nudge_x = -.06,
                            nudge_y = .03) +
  # Colors and label formatting follow
  #coord_flip() +
  scale_colour_gradient(low = "#E0FEA9", high = "#144A11") +
  labs(title = "Poverty to Tree Canopy",
       subtitle = "Percent of households living below the poverty line \ncompared to the percent of tree cover in the area",
       x = "Percent of households living below the poverty line",
       y = "Percent of land covered by trees") +
  scale_x_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  scale_y_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 12))


```

### Fact: 

"Crime rates are higher, so many people won’t put an air-conditioning unit in a first-floor window for fear of break-ins."

#### Explanation

The first set of code returns a dataset with Baltimore's neighborhoods in order from highest average afternoon temperature to lowest. The third column, "part_1_crime_rate_per_1_000_residents", lists the amount of part 1 crimes per 1,000 residents in that neighborhood. Part 1 crimes are considered to be major crimes and for the this dataset include violent crime, shootings, gun, assault and narcotics. 

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("temp_")) %>%
  mutate(variable=rowname) %>%
  select(variable, temp_mean_aft) %>%
  filter(str_detect(variable, "crime|shootings|gun|assault|narcotics"))


csa_tree_temp_demographics %>%
  select(csa2010,temp_mean_aft,matches("crime|shootings|gun|assault|narcotics")) %>%
  arrange(desc(temp_mean_aft))

# CSAs to call out
callout_ls <- c("Canton", "Clifton-Berea", "Greater Roland Park/Poplar Hill", "Greenmount East")

## PROPERTY CRIME TO TEMPERATURE
csa_tree_temp_demographics %>%
  mutate_at(vars("csa2010"), str_to_title) %>%
  # Start ggplot and set x and y for entire plot
  ggplot(aes(
    x = property_crime_rate_per_1_000_residents,
    y = temp_mean_aft
    )) +
  # This section for the basic scatterplot
  geom_point(aes(color = temp_mean_aft),
             size=4) +
  # This section for circling all sample neighborhood points
  geom_point(data = csa_tree_temp_demographics %>%
               mutate_at(vars("csa2010"), str_to_title) %>%
               filter((csa2010 %in% callout_ls)
                      # Patterson Park must be included seperately because of its unique label positioning
                      | (csa2010 == "Patterson Park North & East")
                      ),
             aes(color = temp_mean_aft),
             size=6, shape = 1) +
  # This section shows the trend line
  geom_smooth(se = FALSE, # Removes gray banding
              method = glm,
              color = "black") +
  # This section for labeling Canton, etc.
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 %in% callout_ls) %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Greenmount East" ~ "Greenmount East \n(includes part of Broadway East)",
                                csa2010 == "Clifton-Berea" ~ "Clifton-Berea \n(includes part of Broadway East)",
                                T ~ csa2010)),
            aes(label = csa2010),
            min.segment.length = .1,
            segment.alpha = .5,
            alpha = .85,
            nudge_x = .05,
            nudge_y = .06) +
  # This section for labeling Patterson Park (so its label can be nudged)
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 == "Patterson Park North & East") %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Patterson Park North & East" ~ "Patterson Park North & East \n(includes most of McElderry Park)",
                                T ~ csa2010)),
                            aes(label = csa2010),
                            min.segment.length = .1,
                            segment.alpha = .5,
                            alpha = .85,
                            nudge_x = -.06,
                            nudge_y = .03) +
  # Colors and label formatting follow
  #coord_flip() +
  scale_colour_gradient(low = "#E0FEA9", high = "#144A11") +
  labs(title = "PROPERTY CRIME TO TEMPERATURE",
       subtitle = "Property Crime per 1,000",
       x = "Property crime per 1000 people",
       y = "mean aft temperature") +
  scale_x_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  scale_y_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 12))


```
