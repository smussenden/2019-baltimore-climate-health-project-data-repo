---
title: "Neighborhoods Analysis"
author: "Roxanne Ready, Sean Mussenden, Theresa Diffendal | Howard Center for Investigative Journalism"
date: "8/6/2019"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    df_print: paged
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 3
---

```{r include=FALSE}
# Save this file and run the following line from the Console to output both HTML and .md formats:
# rmarkdown::render('documentation/neighborhoods-data-analysis.Rmd', output_format = 'all')
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, paged.print=TRUE)
```

## Introduction

REWRITE
This R markdown document describes the methodology and results of a portion of the data analysis we conducted in support of a reporting project examining the effects of tree canopy inequity across the city of Baltimore, especially as it relates to climate change.

In general, this document contains the data facts stated in the "Neighborhoods" story. The quote from the story appears first, followed by an explanation of the fact and the code which generated the fact. The code is listed last. The quotes are listed in the order they appear in the Neighborhoods story.

## Setup

Before running this file, **please view and run the [Code Red Data Cleaning document](https://github.com/smussenden/2019-baltimore-climate-health-project-data-repo/blob/master/documentation/code-red-data-cleaning.md)** for this project. As well as outputting necessary cleaned data for the following ananlysis, that document also includes the following items necessary to understand this analysis: 

* definitions
* source data citation and information
* cleaning methodology 
* software tools used

### Load packages

```{r}
#######################
#### Load Packages ####
#######################

library(tidyverse)
library(DescTools) # For %like% operator
library(corrr) # For correlation matrices
library(colorspace) # For improved color palettes
library(ggplot2) # For graphing
library(ggrepel) # For graph labeling
library(lubridate) # For working with and mutating dates
require(scales) # For percent labeling on distribution tables

# Turn off scientific notation in RStudio (prevents coersion to character type)
options(scipen = 999)
```

### Load variables and data

```{r}
#########################
#### Store Variables ####
#########################

#### Common path to data ####
path_to_data <- "../data/output-data/cleaned/"

#### Common save path ####
save_path <- "../data/output-data/cleaned/"

###################
#### Load Data ####
###################

dmh <- read_csv(paste0(path_to_data, "dmh.csv"))
EMS_all <- read_csv(paste0(path_to_data, "EMS_all.csv"))
dmh_ems <- read_csv(paste0(path_to_data, "dmh_ems.csv"))
stephanie_day_averages<- read_csv(paste0(path_to_data, "stephanie_day_averages.csv"))
stephanie_day_hourly_averages <- read_csv(paste0(path_to_data, "stephanie_day_hourly_averages.csv"))
stephanie_day_minute_averages <- read_csv(paste0(path_to_data, "stephanie_day_minute_averages.csv"))
tammy_day_averages <- read_csv(paste0(path_to_data, "tammy_day_averages.csv"))
tammy_day_hourly_averages <- read_csv(paste0(path_to_data, "tammy_day_hourly_averages.csv"))
tammy_day_minute_averages <- read_csv(paste0(path_to_data, "tammy_day_minute_averages.csv"))
michael_day_averages<- read_csv(paste0(path_to_data, "michael_day_averages.csv"))
michael_day_hourly_averages <- read_csv(paste0(path_to_data, "michael_day_hourly_averages.csv"))
michael_day_minute_averages <- read_csv(paste0(path_to_data, "michael_day_minute_averages.csv"))
nsa_tree_temp <- read_csv(paste0(path_to_data,"nsa_tree_temp.csv"))
csa_tree_temp_demographics <- read_csv(paste0(path_to_data,"csa_tree_temp_demographics.csv"))
blocks_tree_temp_demographics <- read_csv(paste0(path_to_data, "blocks_tree_temp_demographics.csv"))

####################################
######## Define Functions ##########
####################################

# Function to save each matrix as CSV
write_matrix_csv <- function(dataframe) {
  # Store dataframe name for later use
  dataframe_name <- deparse(substitute(dataframe))
  
  # Create filename for csv
  filename <- paste0("data/output-data/correlation_matrices/", dataframe_name,".csv")
  
  # Write out csv  
  write_csv(dataframe, path = filename)
  
} 

# Function to make a nice little correlation matrix heatmap for each graphic

make_correlation_matrix_graphic <- function(dataframe, grouping = "GROUPING") {
  
  # Store name of dataframe for use in title
  dataframe_name <- deparse(substitute(dataframe))
  
  # Build chart title
  chart_title <- paste0("Correlations by ", grouping, " in Baltimore City | ", dataframe_name )
  
  # Create graph
  ggplot(data = dataframe, aes(x = variable_2, y = variable)) +
    geom_tile(aes(fill = value)) +
    scale_fill_gradient2(low = "blue", high = "red", mid="white", midpoint=0) +
    geom_text(aes(label = round(value, 2)*100), size = 10) +
    ggtitle(chart_title) +
    theme(axis.text=element_text(size=14),
          axis.text.x = element_text(size=14,angle=50,hjust=1),
          plot.title = element_text(size=14)
    )
  # Create filename and filepath to save image. 
  filename <- paste0(dataframe_name,".png")
  ggsave(filename, plot = last_plot(), device = "png", path = "data/output-data/plots/correlation-matrix-images", scale = 1, width = 20, height = 20, units = "in", dpi = 300)
  
}  

select_x <- function(df){
  return(df %>%
           select_if(is.numeric) 
           # select(-matches("objectid"), 
           #        -matches("csa2010"), 
           #        -matches("id"), 
           #        -matches("09"), 
           #        -matches("1718"), 
           #        -matches("change_percent")
           #        )
         )
}

```

## Line-By-Line Fact-Check

### Fact: 11-Day Heat Wave

"...a dangerous, 11-day heat wave tormented the city this summer..."

#### Explanation

By running the code below, you can see July 12-22 had max temperatures of at least 90 degrees and max heat indexes of at least 92, hence the 11-day heat wave

#### Supporting Code
```{r}

 dmh %>%
  filter(month == 7,
         year == 2019) %>%
  group_by(`date`) %>%
  summarise(min_temp = min(avg_hourly_temperature_dmh),
            max_temp = max(avg_hourly_temperature_dmh),
            mean_temp = mean(avg_hourly_temperature_dmh),
            min_heat_index = min(avg_hourly_heat_index_dmh),
            max_heat_index = max(avg_hourly_heat_index_dmh),
            mean_heat_index = mean(avg_hourly_heat_index_dmh) 
  )


```

### Fact: Inner Harbor Hit 100 Degrees

"“Can’t even put your head out the door,” said Tammy Wilson Jackson, 48, on a day when the temperature at the Inner Harbor hit 100 degrees."

#### Explanation

Our data below shows that the inner harbor hit a max temperature of 100 on Sunday 7/21. There is no other day in our data when the max temperature was 100. However our data uses hourly averages. The National Climatic Data Center also takes weather data hour by hour, but instead of calculating the average the NCDC records the conditions at the exact time of the reading. NCDC also has daily summaries detailing the maximum and minimum temperature experienced over the entire day and the amount of precipitation in inches. Using the NCDC's daily summaries for the month of July 2019, there are two days when the max temperature hit at least 100: 7/20 and 7/21. 

Note: the max temperature on 7/30 was also 100 degrees, but this interview was before then.

#### Supporting Code
```{r}

 dmh %>%
 filter(month == 7,
         year == 2019) %>%
  group_by(`date`) %>%
  summarise(min_temp = min(avg_hourly_temperature_dmh),
            max_temp = max(avg_hourly_temperature_dmh),
            mean_temp = mean(avg_hourly_temperature_dmh),
            min_heat_index = min(avg_hourly_heat_index_dmh),
            max_heat_index = max(avg_hourly_heat_index_dmh),
            mean_heat_index = mean(avg_hourly_heat_index_dmh) 
  )


```

### Fact: McElderry Park is 8 Degrees Hotter

"data show that temperatures here [McElderry Park] and in surrounding neighborhoods can run 8 degrees hotter than in communities that have more trees and less pavement."

#### Explanation

The code below selects part of the dataframe "nsa_tree_temp" - which lists Baltimore neighborhoods and a variety of temperature data - and filters it for the neighborhoods with the lowest average temperature in the afternoon or the highest average temperature in the afternoon. The results are then arranged in descending order. From this data we can see that McElderry Park has the highest average temperature in the afternoon at 99.39 degrees. Dickeyville, on the other hand, has the lowest average afternoon temperature at 91.01 degrees. The difference between those temperatures is 8.38 degrees, which is rounded to 8.

*Note: Gwynns Falls/Leakin Park was removed from the dataset as the topography of the area is more akin to a park than neighborhood.

#### Supporting Code
```{r}
nsa_tree_temp %>%
  select(nsa_name, temp_mean_aft) %>%
  filter(nsa_name != "gwynns falls/leakin park") %>%
  filter((temp_mean_aft == min(temp_mean_aft)) | (temp_mean_aft == max(temp_mean_aft))) %>%
  arrange(desc(temp_mean_aft))
  
```

### Fact: McElderry Park is the hottest neighborhood in Baltimore

"McElderry Park ... which despite its lyrical name offers little green space, is the hottest neighborhood in Baltimore."

#### Explanation

Similar to above, the code below selects the neighborhood and average afternoon temperature columns from the dataframe "nsa_tree_temp" - which lists Baltimore neighborhoods and a variety of temperature data. The results are then arranged in descending order so the hottest neighborhood is at the top. From this data we can see that McElderry Park has the highest average temperature in the afternoon at 99.39 degrees. 

#### Supporting Code
```{r}
nsa_tree_temp %>%
  select(nsa_name, temp_mean_aft) %>%
  arrange(desc(temp_mean_aft))
  
```

### Fact: Frequency of EMS Calls Increase with Temperature

"In hot weather, emergency medical calls for some chronic conditions increase."

#### Explanation

The initial code below sorts the number of calls to EMS into groups based on the outside temperature when the call was made. You'll see that calls for help decrease as temperature increases. 

The second bit of code, however, breaks the calls down by the illness for which the call was made and counts the number of calls per condition during each temperature "bucket." Many of these illness were selected since hot weather tends to aggravate their symptoms/conditions. These numbers show that calls decrease as temperature increases, but a likely explanation is that hot temperatures occur much less frequently than cooler ones, limiting the amount of time when calls can be made in that temperature "bucket." 

To account for the rarity of hotter temperatures, the number of hours for which the temperature was in a certain bucket is divided by the total amount of calls. This will give us the frequency of calls, represented as "hours_per_call." In examining this value per condition per temperature bucket, the data shows that the freqeuency of many calls increases during hotter weather. 

For example, when the temperature is below 80 degrees, a call is made to EMS concerning dehydration every 41.74 hours. When the temperature climbs into the "danger" zone, or 103 to 124 degrees, the rate of calls for dehydration increases to one every 2.21 hours. Similarly, a call for a seizure is made every 2.34 hours when the temperature is less than 80 degrees, but increases to a call every 1.4 hours when the temperature is between 103 and 124 degrees. 

Other conditions for which the call frequency increases include: altered level of consciousness, behavioral/psychiatric disorder, cardiac arrest, chest pain - STEMI, COPD, dehydration, diabetic hyper- and hypoglycemia, dizziness/vertigo, hyper- and hypotension, hyperthermia, obvious death, substance/drug abuse, and others.

#### Supporting Code
```{r}

# Five-part NWS heat index danger scale
heat_index_count_per_nws_five_scale_bucket <- dmh_ems %>%
  select(heat_index_nws_five_scale_bucket) %>%
  group_by(heat_index_nws_five_scale_bucket) %>%
  summarise(heat_index_count_per_nws_five_scale_bucket=n()) %>%
  arrange(heat_index_nws_five_scale_bucket)

########### Five NWS Buckets #################
#### Table 1 | Primary Impression Group | Ratio Condition Calls v Heat Index | five NWS Buckets #####
# Ratio of number of calls for each condition type in each heat index bucket to total number of hours in each given temperature bucket. A lower number indicates a higher number of calls for each condition adjusted for the fact that some temperatures are simply more common than other others. It's 70 degrees for many more hours in a year than it is 110.  

call_heat_index_ratio_five_primary_impression_group <- EMS_all %>%
  filter(primary_impression_group != "Other") %>%
  group_by(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket) %>%
  summarise(condition_calls_count_per_bucket=n()) %>%
  inner_join(heat_index_count_per_nws_five_scale_bucket, by = c("adjusted_heat_index_nws_five_scale_bucket" = "heat_index_nws_five_scale_bucket")) %>%
  mutate(hours_per_call = heat_index_count_per_nws_five_scale_bucket/condition_calls_count_per_bucket) %>%
  select(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  spread(adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  select(primary_impression_group, `not_unsafe_under_80`,`caution_80_89`,`extreme_caution_90_102`,`danger_103_124`)

```

### Fact: Frequency of Diabetes Calls Increases with Temperature

"The rate of emergency medical calls for cardiac arrest and congestive heart failure, for example, nearly double when the heat index hits 103 degrees."

#### Explanation

Using the same code as above, the number of hours inbetween calls for diabetes are certain temperatures was calculated. At 80 degrees or below, a call was made every 5.3 hours for Cardiac Arrest and every 15 hours for Congestive Heart Failure. When the heat index is 103 or greater, however, there is a call to EMS for cardiac arrest every 2.94 hours and for congestive heart failure every 8.83 hours. By dividing the value at 80 degrees by the value at 103+, we will get 1.8 for cardiac arrest and 1.7 for congestive heart failure. Those numbers round to 2, which means the frequency of the calls nearly doubles. 

#### Supporting Code
```{r}

# Create dataframes with a count of hourly heat_index readings for each bucket ###

# Five-part NWS heat index danger scale
heat_index_count_per_nws_five_scale_bucket <- dmh_ems %>%
  select(heat_index_nws_five_scale_bucket) %>%
  group_by(heat_index_nws_five_scale_bucket) %>%
  summarise(heat_index_count_per_nws_five_scale_bucket=n()) %>%
  arrange(heat_index_nws_five_scale_bucket)

########### Five NWS Buckets #################
#### Table 1 | Primary Impression Group | Ratio Condition Calls v Heat Index | five NWS Buckets #####
# Ratio of number of calls for each condition type in each heat index bucket to total number of hours in each given temperature bucket. A lower number indicates a higher number of calls for each condition adjusted for the fact that some temperatures are simply more common than other others. It's 70 degrees for many more hours in a year than it is 110.

call_heat_index_ratio_five_primary_impression_group <- EMS_all %>%
  filter(primary_impression_group != "Other") %>%
  group_by(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket) %>%
  summarise(condition_calls_count_per_bucket=n()) %>%
  inner_join(heat_index_count_per_nws_five_scale_bucket, by = c("adjusted_heat_index_nws_five_scale_bucket" = "heat_index_nws_five_scale_bucket")) %>%
  mutate(hours_per_call = heat_index_count_per_nws_five_scale_bucket/condition_calls_count_per_bucket) %>%
  select(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  spread(adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  select(primary_impression_group, `not_unsafe_under_80`,`caution_80_89`,`extreme_caution_90_102`,`danger_103_124`) %>%
  filter(primary_impression_group == "Cardiac Arrest" | primary_impression_group == "CHF (Congestive Heart Failure)")

```

### Fact: Hot Neighborhoods Have Lower Incomes

"Households in the city’s hottest neighborhoods have lower incomes"

#### Explanation

The code below pulls from the "csa_tree_temp_demographics" dataset, which includes a variety of information on each neighborhood in Baltimore. From that dataset, median afternoon temperature and percentage of family households below the poverty line are isolated to allow for a comparison of median temperatures to poverty rate. The temperature is arranged in descending order, putting the hottest neighborhoods on top. 

The two hottest neighborhoods, Madison/East End and Oldtown/Middle East, have poverty rates of 33.74% and 40.13%, respectively. The ten hottest neighborhoods all have average afternoon temperatures of at least 96 (when rounded) and only two have single digit poverty rates; the poverty rates for the other neighborhoods are all at least 19%. 

In comparison, the 15 coolest neighborhoods have an average afternoon temperature of 94.1 degrees or less. The highest poverty rate is 19.53% in Greater Govans and 19.26% in Forest Park/Walbrook, only greater than the poverty rating of 7 of the 10 hottest neighborhoods. 8 of the coolest neighborhoods have a single digit poverty rating (or 7 neighborhoods, if you round Cross-Country/Cheswolde's poverty rate to 10%).

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("temp_")) %>%
  mutate(variable=rowname) %>%
  select(variable, temp_median_aft) %>%
  filter(variable=="percent_of_family_households_living_below_the_poverty_line")

csa_tree_temp_demographics %>%
  select(csa2010,temp_median_aft,percent_of_family_households_living_below_the_poverty_line) %>%
  arrange(desc(temp_median_aft))

```

### Fact: Unreliable Public Transportation

"Public transportation, which many residents here use, is unreliable."

#### Explanation

The code below returns Baltimore neighborhoods in descending order of average afternoon temperature as well as the percentage of that neighborhood's population that uses public transportation to get to work. Of all the neighborhoods, only 10 have single digit values for the percentage of population that uses public transportation. Of the top ten hottest neighborhoods, only one has a single digit public transportation usage value; the next lowest is 12.20% and the greatest is 42.55%. Over 30% of the population uses public transportation in 10 neighborhoods, and five of those neighbors are also among the ten hottest (six of the highest public transportation using neighborhoods are also among the 12 hottest). 

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("temp_")) %>%
  mutate(variable=rowname) %>%
  select(variable, temp_median_aft) %>%
  filter(variable=="percent_of_population_that_uses_public_transportation_to_get_to_work")

csa_tree_temp_demographics %>%
  select(csa2010,temp_median_aft,percent_of_population_that_uses_public_transportation_to_get_to_work) %>%
  arrange(desc(temp_median_aft))

```

### Fact: More Affluence = More Tree Canopy

"The streets have fewer trees than those in more affluent communities."

#### Explanation

The code below below selects from the neighborhood demographic dataset all the neighborhoods, the poverty rate in those neighborhoods, and the percentage of tree cover for each neighborhood according to the most recent LiDar data available for Baltimore from 2015. The selected observations are then listed in order of greatest tree canopy percentage to least.

The ggplot code then graphs that dataset, with special attention paid to the neighborhoods Canton, Clifton-Berea, Patterson Park, Greater Roland Park/Poplar Hill and Greenmount East. Along the y-axis is percentage of tree canopy coverage while the x-axis shows poverty rates. The code geom_smooth() creates a best fit line over the data and clearly shows a decrease in tree canopy coverage as poverty rate increases.

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("15_lid_mean")) %>%
  mutate(variable=rowname) %>%
  select(variable, `15_lid_mean`) %>%
  filter(variable=="percent_of_family_households_living_below_the_poverty_line")

csa_tree_temp_demographics %>%
  select(csa2010,`15_lid_mean`,percent_of_family_households_living_below_the_poverty_line) %>%
  arrange(desc(`15_lid_mean`))

# CSAs to call out
callout_ls <- c("Canton", "Clifton-Berea", "Greater Roland Park/Poplar Hill", "Greenmount East")

## POVERTY TO TREE COVER
csa_tree_temp_demographics %>%
  mutate_at(vars("csa2010"), str_to_title) %>%
  # Start ggplot and set x and y for entire plot
  ggplot(aes(
    x = percent_of_family_households_living_below_the_poverty_line/100,
    y = `15_lid_mean`
    )) +
  # This section for the basic scatterplot
  geom_point(aes(color = `15_lid_mean`),
             size=4) +
  # This section for circling all sample neighborhood points
  geom_point(data = csa_tree_temp_demographics %>%
               mutate_at(vars("csa2010"), str_to_title) %>%
               filter((csa2010 %in% callout_ls)
                      # Patterson Park must be included seperately because of its unique label positioning
                      | (csa2010 == "Patterson Park North & East")
                      ),
             aes(color = `15_lid_mean`),
             size=6, shape = 1) +
  # This section shows the trend line
  geom_smooth(se = FALSE, # Removes gray banding
              method = glm,
              color = "black") +
  # This section for labeling Canton, etc.
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 %in% callout_ls) %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Greenmount East" ~ "Greenmount East \n(includes part of Broadway East)",
                                csa2010 == "Clifton-Berea" ~ "Clifton-Berea \n(includes part of Broadway East)",
                                T ~ csa2010)),
            aes(label = csa2010),
            min.segment.length = .1,
            segment.alpha = .5,
            alpha = .85,
            nudge_x = .05,
            nudge_y = .06) +
  # This section for labeling Patterson Park (so its label can be nudged)
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 == "Patterson Park North & East") %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Patterson Park North & East" ~ "Patterson Park North & East \n(includes most of McElderry Park)",
                                T ~ csa2010)),
                            aes(label = csa2010),
                            min.segment.length = .1,
                            segment.alpha = .5,
                            alpha = .85,
                            nudge_x = -.06,
                            nudge_y = .03) +
  # Colors and label formatting follow
  #coord_flip() +
  scale_colour_gradient(low = "#E0FEA9", high = "#144A11") +
  labs(title = "Poverty to Tree Canopy",
       subtitle = "Percent of households living below the poverty line \ncompared to the percent of tree cover in the area",
       x = "Percent of households living below the poverty line",
       y = "Percent of land covered by trees") +
  scale_x_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  scale_y_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 12))


```

### Fact: 

"Crime rates are higher, so many people won’t put an air-conditioning unit in a first-floor window for fear of break-ins."

#### Explanation

The first set of code returns a dataset with the amount of various crimes per 1000 residents. The crimes include part 1 crimes, violent crimes, property crimes, shootings, gun related homicides, common assault, and narcotics. The next column, titled "temp_mean_aft", lists the coefficient  of the crime rate to temperature. The closer the coefficient is to 1, the greater the relation. 

The crime rates are then paired with Baltimore's neighborhoods, which are sorted from highest average afternoon temperature to lowest. The third column, "part_1_crime_rate_per_1_000_residents", lists the amount of part 1 crimes per 1,000 residents in that neighborhood.

The values are then plotted, with average afternoon temperature on the y-axis and number of property crimes per 1,000 residents on the x-axis. The neighborhoods Canton, Clifton-Berea, Greater Roland Park/Poplar Hill, Greenmount East and Patterson Park North and East are highlighted for storytelling purposes. A best fit line is applied to show the average trajectory of the plotted values. It has a positive slope, which shows that as crime rate rises, so too does the average afternoon temperature. 

#### Supporting Code
```{r}
 csa_tree_temp_demographics %>%
  select_x() %>%
  as.matrix() %>%
  correlate() %>%
  focus(matches("temp_")) %>%
  mutate(variable=rowname) %>%
  select(variable, temp_mean_aft) %>%
  filter(str_detect(variable, "crime|shootings|gun|assault|narcotics"))


csa_tree_temp_demographics %>%
  select(csa2010,temp_mean_aft,matches("crime|shootings|gun|assault|narcotics")) %>%
  arrange(desc(temp_mean_aft))

# CSAs to call out
callout_ls <- c("Canton", "Clifton-Berea", "Greater Roland Park/Poplar Hill", "Greenmount East")

## PROPERTY CRIME TO TEMPERATURE
csa_tree_temp_demographics %>%
  mutate_at(vars("csa2010"), str_to_title) %>%
  # Start ggplot and set x and y for entire plot
  ggplot(aes(
    x = property_crime_rate_per_1_000_residents,
    y = temp_mean_aft
    )) +
  # This section for the basic scatterplot
  geom_point(aes(color = temp_mean_aft),
             size=4) +
  # This section for circling all sample neighborhood points
  geom_point(data = csa_tree_temp_demographics %>%
               mutate_at(vars("csa2010"), str_to_title) %>%
               filter((csa2010 %in% callout_ls)
                      # Patterson Park must be included seperately because of its unique label positioning
                      | (csa2010 == "Patterson Park North & East")
                      ),
             aes(color = temp_mean_aft),
             size=6, shape = 1) +
  # This section shows the trend line
  geom_smooth(se = FALSE, # Removes gray banding
              method = glm,
              color = "black") +
  # This section for labeling Canton, etc.
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 %in% callout_ls) %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Greenmount East" ~ "Greenmount East \n(includes part of Broadway East)",
                                csa2010 == "Clifton-Berea" ~ "Clifton-Berea \n(includes part of Broadway East)",
                                T ~ csa2010)),
            aes(label = csa2010),
            min.segment.length = .1,
            segment.alpha = .5,
            alpha = .85,
            nudge_x = .05,
            nudge_y = .06) +
  # This section for labeling Patterson Park (so its label can be nudged)
  ggrepel::geom_label_repel(data = csa_tree_temp_demographics %>%
                              mutate_at(vars("csa2010"), str_to_title) %>%
                              filter(csa2010 == "Patterson Park North & East") %>%
                              mutate(csa2010 = case_when(
                                csa2010 == "Patterson Park North & East" ~ "Patterson Park North & East \n(includes most of McElderry Park)",
                                T ~ csa2010)),
                            aes(label = csa2010),
                            min.segment.length = .1,
                            segment.alpha = .5,
                            alpha = .85,
                            nudge_x = -.06,
                            nudge_y = .03) +
  # Colors and label formatting follow
  #coord_flip() +
  scale_colour_gradient(low = "#E0FEA9", high = "#144A11") +
  labs(title = "PROPERTY CRIME TO TEMPERATURE",
       subtitle = "Property Crime per 1,000",
       x = "Property crime per 1000 people",
       y = "mean aft temperature") +
  scale_x_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  scale_y_continuous(label = scales::percent_format(accuracy = 1.0),
                     breaks = seq(0, 1, .1)) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 12))


```

### Fact: Highset Sensor Values

"Reporters from the University of Maryland’s Howard Center for Investigative Journalism and Capital News Service placed sensors that record heat and humidity inside several homes in McElderry Park and nearby neighborhoods.

"Those sensors recorded temperatures that reached as high as 97 degrees and heat index values of 119 degrees."

#### Explanation

The code belowing uses the "all_sensors_day_minute_averages" dataset, which contains all of the temperature and heat index data collected by sensors that reporters from the University of Maryland’s Howard Center for Investigative Journalism and Capital News Service placed in consenting peoples' homes. The values are then filtered, first for the maximum indoor temperature and then for maximum indoor heat index. The two filtered lines return observations of 96.8 degrees (97 when rounded) for maximum temperature and 119 for maximum indoor heat index.

#### Supporting Code
```{r}

all_sensors_day_minute_averages <- bind_rows(michael_day_minute_averages, tammy_day_minute_averages, stephanie_day_minute_averages)

all_sensors_day_minute_averages %>%
  filter(mean_indoor_temperature == max(mean_indoor_temperature))

all_sensors_day_minute_averages %>%
  filter(mean_indoor_heat_index == max(mean_indoor_heat_index))


```

### Fact: Jackson's House's Heat Index was 94 on 7/21

"On the first floor of Jackson’s two-story rowhouse, the heat index registered 93 degrees at 10 p.m. on Sunday, July 21. Outside, the heat index was 9 degrees lower, 84 degrees."

#### Explanation

The following code pulls from datasets containing the average weather condition recordings from sensors for Tammy Jackson's house. The first set uses the hourly average values while the second uses the average recorded values each minute. Both are filtered for July 21, 2019 at 10 p.m. on the dot. Both have the indoor heat index listed as 93 while the outdoor heat index is 84.

#### Supporting Code
```{r}
tammy_day_hourly_averages %>%
  mutate(date = date(date_hour)) %>%
  mutate(hour = hour(date_hour)) %>%
  filter(date == "2019-07-21") %>%
  filter(hour == 22)

tammy_day_minute_averages %>%
  mutate(date = date(date_hour_minute)) %>%
  mutate(hour = hour(date_hour_minute)) %>%
  mutate(minute = minute(date_hour_minute)) %>%
  filter(date == "2019-07-21") %>%
  filter(hour == 22) %>%
  filter(minute == 0)

```

### Fact: 

"At 7 p.m. Friday, the heat index in Baltimore hit 107 degrees in the Inner Harbor. Inside the bedroom Stephanie Pingley’s niece shares with one of her three sons, it was 9 degrees hotter, with a heat index of 116 degrees."

Note: DIFFERENT VALUES, FIX THESE.

#### Explanation

The following code pulls from datasets containing the average weather condition recordings from sensors for Stephanie Pingley's house. The first set uses the hourly average values while the second uses the average recorded values each minute. Both are filtered for July 19, 2019 at 7 p.m. on the dot. The heat index for the hourly averages table is 115.7 degrees, while on the minute table the heat index is listed as 115.

The final set of code accesses the dataset containing average hourly temperatures, dewpoints, relative humidities, and heat indexes for Baltimore's Inner Harbor since 1998. The data is filtered for July 19 at 7 p.m., at which time the average heat index was listed as 103.

#### Supporting Code
```{r}

stephanie_day_hourly_averages %>%
  mutate(date = date(date_hour)) %>%
  mutate(hour = hour(date_hour)) %>%
  filter(date == "2019-07-19") %>%
  filter(hour == 19)

stephanie_day_minute_averages %>%
  mutate(date = date(date_hour_minute)) %>%
  mutate(hour = hour(date_hour_minute)) %>%
  mutate(minute = minute(date_hour_minute)) %>%
  filter(date == "2019-07-19") %>%
  filter(hour == 19) %>%
  filter(minute == 0)

dmh %>%
  filter(date == "2019-07-19",
         hour == 19) %>%
  select(avg_hourly_heat_index_dmh)

```

### Fact: Thomas' House was 96 on 7-20

"By Saturday, the temperature inside the second-floor apartment of Michael Thomas and Alberta Wilkerson hit 96 degrees."

#### Explanation

The following code pulls from datasets containing the average weather condition recordings from sensors for Michael's house. The first sorts in descending order of mean_indoor_temperature values while the second sorts in descending order of mean_indoor_heat_index values. Both are filtered for July 20, 2019. Both sets contain a value of 96 or greater for the mean_indoor_temperature at least once during the day.

Note: The heat index hit 112!

#### Supporting Code
```{r}

michael_day_hourly_averages %>%
  mutate(date = date(date_hour)) %>%
  mutate(hour = hour(date_hour)) %>%
  filter(date == "2019-07-20") %>%
  arrange(desc(mean_indoor_temperature))

michael_day_hourly_averages %>%
  mutate(date = date(date_hour)) %>%
  mutate(hour = hour(date_hour)) %>%
  filter(date == "2019-07-20") %>%
  arrange(desc(mean_indoor_heat_index))

```

### Fact: Pingley's Indoor Heat Index Greater than Outdoor

"A sensor inside a bedroom showed that the heat index during the heat wave was consistently higher inside than outside Pingley’s house."

#### Explanation

The following code pulls from datasets containing the average weather condition recordings from sensors in Stephanie Pingley's house. The first set uses the hourly average values, which is then filtered for the days during which the heat wave occurred, July 14-23. From that dataset, the outdoor heat index values are plotted in purple alongside indoor heat index values in red. The x-axis shows degrees while the y-axis shows dates. The red line for indoor heat index values is consistently higher than the outdoor heat index values line, showing that the heat index inside Pingley's house was often greater than the heat index outdoors.

#### Supporting Code
```{r}

stephanie_day_hourly_averages %>%
  mutate(hourly_mean_group = "hourly_mean_group") %>%
  group_by(hourly_mean_group) %>%
  summarise(mean_indoor_heat_index_differnence = mean(indoor_heat_index_difference))

stephanie_day_hourly_averages_heat_wave <- stephanie_day_hourly_averages %>%
  mutate(date = date(date_hour)) %>%
  filter(date >= "2019-07-14") %>%
  filter(date <= "2019-07-23")

chart_title <- "hourly averages"
  temp_hourly_graph <- ggplot() +
    geom_line(data = stephanie_day_hourly_averages_heat_wave, aes(x = date_hour, y = mean_indoor_heat_index, colour="indoor heat index (f)")) +
    geom_line(data = stephanie_day_hourly_averages_heat_wave, aes(x = date_hour, y = mean_outdoor_heat_index, colour="outdoor heat index (f)")) +
    scale_color_manual(
      values = c('indoor heat index (f)' = 'red',
                 'outdoor heat index (f)' = 'purple')
    ) +
    ggtitle(chart_title) +
    xlab("day (hours)") +
    ylab("degrees (f)") +
    scale_x_datetime(date_breaks = "1 day") +
    theme(axis.text.x = element_text(angle=50,hjust=1))
  plot(temp_hourly_graph)

```

### Fact: East Baltimore Tree Cover

"And in 2015, many East Baltimore neighborhoods had a tree canopy of about 10%, according to a Howard Center analysis of tree canopy data gathered by researchers at the U.S. Forest Service and the University of Vermont."

More accurate to say that in East Baltimore, most had less than 10 percent.

#### Explanation

The following code selects neighborhoods in East Baltimore and arranges them in ascending order of tree canopy coverage as determined by the 2015 LiDar flyover data for Baltimore, the most recent data. 11 of the 15 neighborhoods have single digit percentage canopy cover, while Oliver with the highest only has 14%, far short of the city's goal of 40% tree cover.

#### Supporting Code
```{r}

east_baltimore_nsas <- c("Berea", "Broadway East", "Oliver", "Middle East",
                 "Biddle Street","Milton-Montford", "Madison-Eastend",
                 "CARE", "McElderry Park", "Ellwood Park/Monument",
                 "Patterson Place", "Patterson Park Neighborhood",
                 "Baltimore Highlands", "Highlandtown",
                 "Upper Fells Point") %>%
  lapply(tolower)

nsa_tree_temp %>%
  filter(nsa_name %in% east_baltimore_nsas) %>%
  select(nsa_name, `15_lid_mean`) %>%
  arrange(`15_lid_mean`) %>%
  mutate(`15_lid_mean_percentage` = 100*(`15_lid_mean`))

```

### Fact: Blocks without Trees

"Many blocks have no trees at all."

#### Explanation

The code below scans the "blocks_trees_temp_demographics" dataset for blocks with 0 tree canopy coverage in 2015 as determined by the 2015 LiDar data. The GeoID is a unique number combining state, county, tract and block identifiers to designate a specific block in Baltimore. Blocks without anyone living on them, as in having a recorded population of 0, are removed from the set. Even after the filtering, 86 blocks remain with a population greater than 0 and 0% tree canopy coverage.

The GeoID 245100803011000 can be broken down into:
        State: 24, for Maryland
        County: 510, for Baltimore
        Tract: 080301
        Block: 1000

#### Supporting Code
```{r}
blocks_tree_temp_demographics %>%
  filter(`15_lid_mean` == 0) %>%
  filter(population_2010 >0) %>%
  filter(aland10 > 0) %>%
  select(geoid10, population_2010, `15_lid_mean`)
```

### Fact: 

"As temperatures at Baltimore’s Inner Harbor reached 100 on July 20, most everyone around..."

* Will have to do this by official records, not our data. Put in link here.

#### Explanation



#### Supporting Code

```{r}

```

## Fact: Temperature vs. Demographics Graphics

These data confirm the graphs found [here](https://amarton.github.io/2019-baltimore-climate-health-project-graphics-repo/heat-demographics-scatterplots/combined-scatterplots.html).

#### Explanation

The data below pulls from the dataset "csa_tree_temp_demographics" which contains information about average temperature, tree canopy coverage, crime rate, poverty levels, and more demographics for neighborhoods in Baltimore. The created subset selects columns for average afternoon temperature, poverty levels, crime rate, life expectancy and unemployment rate. The data is then plotted. Temperature is plotted on the x-axis, with the other values on the y-axis for a total of four different graphs. The graphs can be seen at the link above. 

#### Supporting Code
```{r}

#### Save working table of only the variables needed for this story ####
wk_csa_tree_temp_demographics <- csa_tree_temp_demographics %>%
  select(matches("csa2010"), matches("temp_mean_aft"),
         perc_below_poverty = matches("percent_of_family_households_living_below_the_poverty_line"),
         matches("violent_crime_rate_per_1_000_residents"), matches("life_expectancy"),
         matches("unemployment_rate")) %>%
  arrange(desc(temp_mean_aft))

#### Save the table to CSV for reference ####
#write_csv(wk_csa_tree_temp_demographics, paste0(save_path, "csa_tree_temp_demographics_truncated.csv"))

#### Remove working table from workspace ####
#rm(wk_csa_tree_temp_demographics)

```

### Fact: Poverty

"Percent of families living below the poverty line compared to mean temperature"

#### Explanation

The first chunk of code below pulls the information on average afternoon temperatures and poverty rate for Baltimore neighborhoods from the larger csa_tree_temp_demographics set. The correlation between temperature values and poverty percentage is calculated by the second chunk of code using a correlation matrix. The correlation works out to about .4; again, the closer to 1 a correlation is, the greater the relationship between one variable and another. .4, while less than half of 1, still indicates some relationship betwen poverty and temperature. 

The poverty and temperature values are mapped, with poverty on the y-axis and temperature on the x-axis. Despite outliers, there is a clear trend showing poverty rates increasing as temperature increases.

There is a `r round(wk_corr[[2, 2]], 2)` correlation between temperature and poverty.

#### Supporting Code
```{r}

#### Data used ####
csa_tree_temp_demographics %>%
  select(matches("csa2010"), matches("temp_mean_aft"),
         perc_below_poverty = matches("percent_of_family_households_living_below_the_poverty_line")) %>%
  arrange(desc(temp_mean_aft))

#### Build correlation matrix ####
wk_corr <- csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         perc_below_poverty = percent_of_family_households_living_below_the_poverty_line) %>%
  as.matrix() %>%
  correlate() %>%
  mutate(variable=rowname) %>%
  select(variable, everything(), -rowname)
#### Print out correlation matrix ####
wk_corr

#### Scatterplot ####
csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         perc_below_poverty = percent_of_family_households_living_below_the_poverty_line) %>%
  ggplot(aes(x = temp_mean_aft, y = perc_below_poverty)) +
  geom_point()

```

### Fact: Crime

"Rates of violent crime per 1,000 residents compared to mean temperature"

#### Explanation

The first chunk of code below pulls the information on average afternoon temperatures and crime rate for Baltimore neighborhoods from the larger csa_tree_temp_demographics set. The correlation between temperature values and crime rate is calculated by the second chunk of code using a correlation matrix. The correlation works out to about .58; again, the closer to 1 a correlation is, the greater the relationship between one variable and another. .58 indicates a moderate relationship betwen poverty and temperature. 

The crime and temperature values are mapped, with crime on the y-axis and temperature on the x-axis. Outside of a few extremes, there is a clear trend showing crime rates increasing as temperature increases.

There is a `r round(wk_corr[[2, 2]], 2)` correlation between temperature and crime.

#### Supporting Code
```{r}

#### Data used ####
csa_tree_temp_demographics %>%
  select(matches("csa2010"), matches("temp_mean_aft"),
         matches("violent_crime_rate_per_1_000_residents")) %>%
  arrange(desc(temp_mean_aft))

#### Build correlation matrix ####
wk_corr <- csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         violent_crime_rate_per_1_000_residents) %>%
  as.matrix() %>%
  correlate() %>%
  mutate(variable=rowname) %>%
  select(variable, everything(), -rowname)
#### Print out correlation matrix ####
wk_corr

#### Scatterplot ####
csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         violent_crime_rate_per_1_000_residents) %>%
  ggplot(aes(x = temp_mean_aft, y = violent_crime_rate_per_1_000_residents)) +
  geom_point()

```

### Fact: Life Expectancy 

"Average life expectancy of neighborhood residents compared to mean temperature"

#### Explanation

The first chunk of code below pulls the information on average afternoon temperatures and life expectancy for Baltimore neighborhoods from the larger csa_tree_temp_demographics set. The correlation between temperature values and life expectancy is calculated by the second chunk of code using a correlation matrix. The correlation works out to about -.41; again, the closer to 1 a correlation is, the greater the relationship between one variable and another. A negative correlation indicates an inverse relationship; as one variable increases, the other decreases. In this case -.41 indicates an inverse relationship betwen life expectancy and temperature. 

The life expectancy and temperature values are mapped, with life expectancy on the y-axis and temperature on the x-axis. There is a trend showing life expectancy decreasing as temperature increases.

There is a `r round(wk_corr[[2, 2]], 2)` correlation between temperature and life expectancy.

#### Supporting Code
```{r}

#### Data used ####
csa_tree_temp_demographics %>%
  select(matches("csa2010"), matches("temp_mean_aft"),
         matches("life_expectancy")) %>%
  arrange(desc(temp_mean_aft))

#### Build correlation matrix ####
wk_corr <- csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         life_expectancy) %>%
  as.matrix() %>%
  correlate() %>%
  mutate(variable=rowname) %>%
  select(variable, everything(), -rowname)
#### Print out correlation matrix ####
wk_corr

#### Scatterplot ####
csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         life_expectancy) %>%
  ggplot(aes(x = temp_mean_aft, y = life_expectancy)) +
  geom_point()

```

### Fact: Unemployment rate

"Unemployment rates among residents compared to mean temperature"

#### Explanation

The first chunk of code below pulls the information on average afternoon temperatures and unemployment rates for Baltimore neighborhoods from the larger csa_tree_temp_demographics set. The correlation between temperature values and unemployment rates is calculated by the second chunk of code using a correlation matrix. The correlation works out to about .32; again, the closer to 1 a correlation is, the greater the relationship between one variable and another. .32 indicates a slight relationship betwen unemployment rates and temperature. 

The unemployment rates and temperature values are mapped, with unemployment rates on the y-axis and temperature on the x-axis. While there are some values showing lower unemployment at higher temperatures, the graph still plots a trend showing that, overall, unemployment rates increase as temperature increases.

There is a `r round(wk_corr[[2, 2]], 2)` correlation between temperature and unemployment rate.

#### Supporting Code
```{r}

#### Data used ####
csa_tree_temp_demographics %>%
  select(matches("csa2010"), matches("temp_mean_aft"),
         matches("unemployment_rate")) %>%
  arrange(desc(temp_mean_aft))

#### Build correlation matrix ####
wk_corr <- csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         unemployment_rate) %>%
  as.matrix() %>%
  correlate() %>%
  mutate(variable=rowname) %>%
  select(variable, everything(), -rowname)
#### Print out correlation matrix ####
wk_corr

#### Scatterplot ####
csa_tree_temp_demographics %>%
  select(temp_mean_aft,
         unemployment_rate) %>%
  ggplot(aes(x = temp_mean_aft, y = unemployment_rate)) +
  geom_point()

```



``` {r include=FALSE}

#### Delete the temporary table used to display correlations in-line ####
rm(wk_corr)
```
