---
title: "EMS calls and summer temperatures in Baltimore"
author: "Sean Mussenden | Howard Center for Investigative Journalism"
date: "7/9/2019"
output: html_document
---

#### TO DO 
--figure out whether we really just want to use last summer, which was pretty uniquely hot and a better look at our future. 
--Talk with Kathy about 5 year data
--Do analysis of last summer temp data
--Adjust ALL heat island data with heat index function using dew point from August 29, 2018

## Introduction

This R markdown document describes the methodology and results of a portion of the data analysis we conducted in support of a reporting project examining the effects of hot summer temperatures on the health of people in Baltimore City, and how climate-change driven temperature increases could exacerbate existing problems. 

## Setup 

```{r results='hide', echo=TRUE, message=FALSE}

#######################
#### Load Packages ####
#######################

library(tidyverse)
library(stringr)
library(lubridate)
library(readxl)
library(janitor)
library(weathermetrics)
```

### About EMS Data
We obtained detailed information from Baltimore City on EMS calls in the city from January 1, 2014 to November 30, 2018 via a public information act request.  The data included location of the call, at the ZIP code level, date and time of the call, the primary medical impression for each patient and other information.  

```{r}

#################################
#### Load EMS Data ##############
#################################

# Read in five CSVs
EMS_2014 <- read.csv("../../data/input-data/baltimore-ems/raw-data/ems-data/csv/2014.csv")
EMS_2015 <- read.csv("../../data/input-data/baltimore-ems/raw-data/ems-data/csv/2015.csv")
EMS_2016 <- read.csv("../../data/input-data/baltimore-ems/raw-data/ems-data/csv/2016.csv")
EMS_2017 <- read.csv("../../data/input-data/baltimore-ems/raw-data/ems-data/csv/2017.csv")
EMS_2018_partial <- read.csv("../../data/input-data/baltimore-ems/raw-data/ems-data/csv/2018-1.1-11.30.csv")

# Bind together into one dataframe

EMS_all <- bind_rows(EMS_2014, EMS_2015, EMS_2016, EMS_2017, EMS_2018_partial)

# Remove all dataframes from our environment but EMS_all, to save space, I supppose

# rm(list=setdiff(ls(), "EMS_all"))

#################################
#### Clean EMS Data #############
#################################

# Rename columns to get rid of funky codes

EMS_all <- EMS_all %>%
  rename(incident_date = Incident.Date,
         incident_number = Incident.Number,
         primary_impression =  Primary.Impression,
         arrived_on_scene_time = Times...Arrived.on.Scene.Time,
         zipcode = Incident.Postal.Code..E8.15.,
         destination_patient_disposition = Destination.Patient.Disposition..E20.10.,
         destination_code = Destination.Code..E20.2.
  )

# Filter EMS_all to remove the dispositions we don't want.

EMS_all <- EMS_all %>%
  filter(destination_patient_disposition != "" &
           destination_patient_disposition != "No Patient Found" &
           destination_patient_disposition != "Cancelled en Route/On Arrival" &
           destination_patient_disposition != "Cancelled Prior to Response" &
           destination_patient_disposition != "Provided ALS personnel to scene, no transport" &
           destination_patient_disposition != "Standby Only - No Patient Contacts" &
           destination_patient_disposition != "Cancelled On Arrival" &
           destination_patient_disposition != "Operational Support Provided Only")

# Remove N/A and blank values
EMS_all <- EMS_all[-which(EMS_all$arrived_on_scene_time=="" | is.na( EMS_all$incident_date) | EMS_all$incident_number=="" | EMS_all$primary_impression=="" | EMS_all$zipcode=="" | EMS_all$destination_patient_disposition==""), ]

# remove all characters from ZIP code field
v1 <- c("1", "2", "3", "4", "5", "6", "7", "8", "9", "0")
EMS_all$zipcode <- gsub(paste0("[^", paste(v1, collapse=""), "]+"), "", EMS_all$zipcode)

# Create an array of Baltimore ZIP codes used in our analysis
balt_zips <- c("21201","21202","21205","21206","21207","21208","21209","21210","21211","21212","21213","21214", "21215","21216","21217","21218","21222","21223","21224","21225","21226","21227","21228","21229", "21230","21231","21234","21236","21237","21239","21251")

# Filter out handful of unneeded ZIPs
EMS_all <- subset(EMS_all, zipcode %in% balt_zips )

# Create full datetime object of arrival time
EMS_all <- EMS_all %>%
  mutate(arrive_time = as.POSIXct(paste(incident_date, arrived_on_scene_time), format="%m/%d/%y %H:%M:%S")) %>%
  select(incident_date, arrived_on_scene_time, arrive_time, everything())

# Add temperature time object that will merge nicely with our temperature data (which is all captured at the 54th minute of every hour) by changing minute to 54, but keeping everything else constant. 
EMS_all <- EMS_all  %>%
  mutate(temp_time = update(arrive_time, minutes = 54, seconds = 0)) %>%
  select(incident_date, arrived_on_scene_time, arrive_time, temp_time, everything())

# Remove seconds from temperature time
EMS_all$temp_time <- format(as.POSIXct(EMS_all$temp_time), "%m-%d-%Y %H:%M")

# Working from the original primary impression field, crated a new field called primary impression group that keeps the names of things we care to examine, and lump everything else into "other" category.  Also create a higher level primary impression category that groups like conditions together.
EMS_all <- EMS_all %>%
  mutate(primary_impression_group = if_else(primary_impression %in% c("Pain", "Other", "Abdominal Pain/Problems", "Weakness", "Other Illness/Injury", "Nausea/Vomiting (Unknown Etiology)", "General Malaise/Sick", "Back Pain (Non-Traumatic)", "Headache", "OB/Gyn - Vaginal Hemorrhage", "Fever", "Unknown Problem", "Poisoning", "Drowning/Near Drowning", "Electrocution", "Inhalation Injury (Toxic Gas)", "Lightening Strike", "Depressurization/Scuba", "SIDS (Sudden Infant Death Syndrome)", "Traumatic Injury", "OB/Gyn - Other", "OB/Gyn - OB/Delivery", "Sepsis",  "Other CNS Problem", "Migraine", "Allergic Reaction", "Abuse / Neglect", "Stings/Venomous Bites", "Airway Obstruction", "Anaphylaxis", "Hypovolemia/Shock", "Overpressurization", "Hazmat Exposure - Chem, Bio, Rad", "Inhalation - Smoke", "Sexual Assault/Rape", "Other Endocrine/Metabolic Problem", "Bowel Obstruction", "Apparent Life-Threatening Event", "Diarrhea", "Burn", "Pregnancy/OB Delivery", "G.I. Bleed", "Other GU Problems", "Patient Assist Only", "Not Applicable", "Other Abdominal/GI Problem", "No Apparent Illness/Injury"), "Other", primary_impression),
         primary_impression_category = case_when(
           primary_impression_group %in% c("ETOH Abuse", "Withdrawal/Overdose ETOH", "Withdrawal/Overdose Drugs", "Altered Level of Consciousness", "Substance/Drug Abuse") ~ "Substance abuse",
           primary_impression_group %in% c("Cardiac Arrest", "Cardiac Rhythm Disturbance", "Hypotension", "Hypertension", "CHF (Congestive Heart Failure)", "Chest Pain/Discomfort", "Chest Pain - STEMI", "Other Cardiovascular Problem", "Abdominal Aortic Aneurysm" ) ~ "Heart/circulatory",
           primary_impression_group %in% c("Heat Exhaustion/Heat Stroke", "Hyperthermia" ) ~ "Acute heat conditions",
           primary_impression_group %in% c("Diabetic Hypoglycemia", "Diabetic Hyperglycemia") ~ "Diabetes complication",
           primary_impression_group %in% c("COPD (Emphysema/Chronic Bronchitis)", "Asthma", "Respiratory Distress", "Respiratory Arrest", "Croup") ~ "Respiratory",
           primary_impression_group %in% c("Stroke/CVA", "TIA (Transient Ischemic Attack)") ~ "Stroke",
           TRUE ~ primary_impression_group
         ))

```
### About Baltimore City Temperature Data
We obtained hour-by-hour Baltimore City temperature data from the National Weather Service's DMH ASOS monitoring station, located in the Inner Harbor next to the Maryland Science Center.  It contains hourly (with some occasional gaps) readings for temperature, humidity, dew point and other variables for DMH for the last 20 years.  We downloaded this data from the very helpful Iowa State University ASOS Network data repository. https://mesonet.agron.iastate.edu/request/download.phtml?network=MD_ASOS


```{r}
#########################
# Load Temperature Data #
#########################

# Load Baltimore Inner Harbor Temperature Data
temp_data <- read_excel("../../data/input-data/baltimore-inner-harbor-temperature/DMH.xlsx")

##########################
# Clean Temperature Data #
##########################

# Build a datetime object from DATE and TIME
temp_data  <- temp_data  %>%
  mutate(temp_time = as.POSIXct(DATETIME, format="%Y-%m-%d %H:%M"))

# Remove seconds from datettime object
temp_data$temp_time <- format(as.POSIXct(temp_data$temp_time), "%m-%d-%Y %H:%M")

# Filter out missing values for temp and humidity and convert to numeric
temp_data <- temp_data %>%
  filter(DEW_POINT != 'M', TEMPERATURE != 'M') %>%
  mutate(DEW_POINT = as.numeric(DEW_POINT),
         TEMPERATURE = as.numeric(TEMPERATURE))

# Calculate Heat Index values  
temp_data <- temp_data %>%
  mutate(HEAT_INDEX = heat.index(t=TEMPERATURE, dp=DEW_POINT, temperature.metric = "fahrenheit", output.metric = "fahrenheit"))

# Round temperature
temp_data <- temp_data %>%
   mutate(TEMPERATURE = round(as.numeric(TEMPERATURE),0))

# Take out handful of inconsistent values that don't match our 54 method, which is to say they were captured at 54 minutes. 
temp_data <- temp_data %>%
  filter(str_detect(temp_time, ":54")) %>%
  filter(TEMPERATURE != 1) %>%
  distinct()

```
## Merge Temperature/Heat Index Data and EMS Data
In order to determine the temperature at the Inner Harbor at the time of each call in the EMS data, we merge the two data sets together.  

```{r}

# Merge data
# Note, of the 581,530 observations in EMS ALL, ~10K failed to join in the merge because we are missing temperature values for those times.  In some cases entire days are missing, in some cases it's a few hours.  Rather than introduce new errors by imputing temperature values, we're going to leave these out.  They are mostly wintertime temps, which are less important for our analysis.
full_data <- inner_join(EMS_all, dmh, by=c("date", "hour"))
```

## Adjust for Urban Heat Island and Calculate Adjusted Heat Index
For each call, we now have the temperature and heat index value as recorded at the Inner Harbor station at the date and time of the call.  But we have not yet accounted for the fact that, in Baltimore City, temperatures can vary greatly between the Inner Harbor and other parts of the city.  We obtained urban heat island raster images, showing block-by-block temperature variations in Baltimore calculated using mobile temperature sensors and satellite data on August 29, 2018. (Citation: Shandas, V.; Voelkel, J.; Williams, J.; Hoffman, J. Integrating Satellite and Ground Measurements for Predicting Locations of Extreme Urban Heat. Climate 2019, 7, 5.  https://osf.io/e63x9/) and processed them in QGIS to obtain median afternoon temperatures for each ZIP code in our analysis.  We then adjusted each call's Inner Harbor temperature to account for the delta between the Inner Harbor monitoring station's ZIP code (21230) temperature in the urban heat island study and each call's ZIP code temperature in the urban heat island study.  Using the adjusted temperature, we recalculated the heat index using the dew point reading captured at the Inner Harbor.   

```{r}
##########################################################
# Adjust for Urban Heat Island and Calculate Heat Index ##
##########################################################

# Load urban heat island data with morning, aft and night median temperature.
urban_heat_zcta <- read_csv("../../data/output-data/cleaned/tree-temp-demographic-w-naip-lidar-use/zcta_clipped_lidartree_temp.csv")

# Convert geoid to zcta and select needed columns
urban_heat_zcta <- urban_heat_zcta %>%
  select(geoid10, temp_median_am, temp_median_aft, temp_median_pm) %>%
  mutate(zcta = geoid10)


# Calculate difference between Inner Harbor (KDMH) station temperature. A positive value in difference columns means warmer than inner harbor KDMH weather station at Science Center. A negative value means cooler.
urban_heat_zcta <- urban_heat_zcta %>%
  mutate(temp_median_am_kdmh_zip = 79.6,
         temp_median_aft_kdmh_zip = 95.3,
         temp_median_pm_kdmh_zip = 89.8,
         am_difference = temp_median_am - temp_median_am_kdmh_zip,
         aft_difference = temp_median_aft - temp_median_aft_kdmh_zip,
         pm_difference = temp_median_pm - temp_median_pm_kdmh_zip,
         zipcode = as.character(zcta)
         ) %>%
  select(zipcode, matches("difference"))

# Join urban_heat_zcta to EMS_all
full_data <- full_data %>%
  clean_names() %>%
  inner_join(urban_heat_zcta, by=c("zipcode"))

# Create columns with adjusted temperature
full_data <- full_data %>%
  mutate(hour = hour(datetime)) %>%
  mutate(adjusted_temperature =
           case_when(hour >= 20 ~ as.character(temperature + pm_difference),
                     hour >= 12 ~ as.character(temperature + aft_difference),
                     hour >= 4 ~ as.character(temperature + am_difference),
                     hour >= 0 ~ as.character(temperature + pm_difference)
                     ),
         adjusted_temperature = round(as.numeric(adjusted_temperature), 0)
      )

# Now that we've adjusted temperature, calculate the adjusted heat index
full_data <- full_data %>%
  mutate(adjusted_heat_index = heat.index(t=adjusted_temperature, dp=dew_point, temperature.metric = "fahrenheit", output.metric = "fahrenheit"))

```
## Create Heat Index Buckets

In order to examine the impact of extreme temperatures on EMS calls, we need to assign each call's adjusted heat index value to one of four temperature buckets we've created to align with the National Weather Service's heat index safety threshold table. https://www.weather.gov/safety/heat-index. 

The NWS heat index formula assumes conditions of light wind and shade, noting that exposure to full sun can increase heat index values by up to 15 degrees. We didn't feel comfortable adjusting heat index values to account for this, so this is where we are.  We were also unable to obtain the necessary data to calculate "wet bulb globe temperature", which the NWS says can be a better measure of heat stress in full sunlight. 

The NWS heat index buckets are:
* < 80 = not unsafe temperatures for heat
* 80-89 = caution
* 90-102 = extreme caution
* 103-124 = danger
* Approximately 125+ = extreme danger 

```{r}

# Create a NWS temperature bucket in our joined calls-temp data set with a five-part NWS temperature danger scale, and a column so we can sort nicely.
full_data <- full_data %>%
  mutate(adjusted_heat_index_nws_five_scale_bucket = case_when(
    adjusted_heat_index <= 79 ~ "not_unsafe_under_80",
    adjusted_heat_index >= 80 & adjusted_heat_index <= 89 ~ "caution_80_89",
    adjusted_heat_index >= 90 & adjusted_heat_index <= 102 ~ "extreme_caution_90_102",
    adjusted_heat_index >= 103 & adjusted_heat_index <= 124 ~ "danger_103_124",
    adjusted_heat_index >= 125 ~ "extreme_danger_125_plus"
  ), adjusted_heat_index_nws_five_scale_bucket_order = case_when(
    adjusted_heat_index_nws_five_scale_bucket == "not_unsafe_under_80" ~ "A",
    adjusted_heat_index_nws_five_scale_bucket == "caution_80_89" ~ "B",
    adjusted_heat_index_nws_five_scale_bucket == "extreme_caution_90_102" ~ "C",
    adjusted_heat_index_nws_five_scale_bucket == "danger_103_124" ~ "D",
    adjusted_heat_index_nws_five_scale_bucket == "extreme_danger_125_plus" ~ "E"
  )
  )

# For later calculations, we're also going to have to create these NWS temperature buckets in our temperature data set.  
temp_data <- temp_data %>%
  mutate(heat_index_nws_five_scale_bucket = case_when(
    HEAT_INDEX <= 79 ~ "not_unsafe_under_80",
    HEAT_INDEX >= 80 & HEAT_INDEX <= 89 ~ "caution_80_89",
    HEAT_INDEX >= 90 & HEAT_INDEX <= 102 ~ "extreme_caution_90_102",
    HEAT_INDEX >= 103 & HEAT_INDEX <= 124 ~ "danger_103_124",
    HEAT_INDEX >= 125 ~ "extreme_danger_125_plus"
  ), heat_index_nws_five_scale_bucket_order = case_when(
    heat_index_nws_five_scale_bucket == "not_unsafe_under_80" ~ "A",
    heat_index_nws_five_scale_bucket == "caution_80_90" ~ "B",
    heat_index_nws_five_scale_bucket == "extreme_caution_90_102" ~ "C",
    heat_index_nws_five_scale_bucket == "danger_103_124" ~ "D",
    heat_index_nws_five_scale_bucket == "extreme_danger_125_plus" ~ "E"
  )
  )

```
## Filter Data Only for Summer Dates
We only want to examine last summer in Baltimore (2018), so we need to filter our full_data and temp_data sets. 

```{r}
full_data <- full_data %>%
filter(`datetime` >= date("2018-06-21") & `datetime` <= ("2018-09-21"))

temp_data <- temp_data %>%
filter(`DATETIME` >= date("2018-06-21") & `DATETIME` <= ("2018-09-21"))

```
## Account for rarity of very hot conditions
Our goal is to determine whether the relative frequency of calls changes when the temperature goes over 103 degrees, the NWS "danger" benchmark.  We could simply count calls for each condition in each temperature bucket and compare them.  But the results would be very skewed, for this simple fact: it's much more likely to be under 80 degrees in Baltimore in the summer than it is over 103.  

For each medical condition in each temperature grouping, we want to calculate the number of hours, on average, per call. Or, to put it another way, we want to determine the average number of hours between calls for each condition in each given temperature range.   

We need to create a new data frame here, which, gives us the number of hours the heat index registered in each bucket during the five summers we observed.  

```{r}

##################################################################################
# Create dataframes with a count of hourly heat_index readings for each bucket ###
##################################################################################

# Five-part NWS heat index danger scale
heat_index_count_per_nws_five_scale_bucket <- temp_data %>%
  select(heat_index_nws_five_scale_bucket) %>%
  group_by(heat_index_nws_five_scale_bucket) %>%
  summarise(heat_index_count_per_nws_five_scale_bucket=n()) %>%
  arrange(heat_index_nws_five_scale_bucket)

########### Five NWS Buckets #################
#### Table 1 | Primary Impression Group | Ratio Condition Calls v Heat Index | five NWS Buckets #####
# Ratio of number of calls for each condition type in each heat index bucket to total number of hours in each given temperature bucket. A lower number indicates a higher number of calls for each condition adjusted for the fact that some temperatures are simply more common than other others. It's 70 degrees for many more hours in a year than it is 110.  

call_heat_index_ratio_five_primary_impression_group <- full_data %>%
  filter(primary_impression_group != "Other") %>%
  group_by(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket) %>%
  summarise(condition_calls_count_per_bucket=n()) %>%
  inner_join(heat_index_count_per_nws_five_scale_bucket, by = c("adjusted_heat_index_nws_five_scale_bucket" = "heat_index_nws_five_scale_bucket")) %>%
  mutate(hours_per_call = heat_index_count_per_nws_five_scale_bucket/condition_calls_count_per_bucket) %>%
  select(primary_impression_group, adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  spread(adjusted_heat_index_nws_five_scale_bucket, hours_per_call) %>%
  select(primary_impression_group, `not_unsafe_under_80`, `caution_80_89`, `extreme_caution_90_102`, `danger_103_124`)

write_csv(call_heat_index_ratio_five_primary_impression_group, "hours_btwn_calls_heat_index.csv")

```



